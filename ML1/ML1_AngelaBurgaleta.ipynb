{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML1_AngelaBurgaleta.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#<font color='magenta'>Aprendizaje de Dígitos </font>\n",
        "**Ángela Burgaleta Ledesma\n",
        "CDAW Feb/2022**\n",
        "\n",
        "El objetivo de esta práctica es aprender con el dataset de digits del Scikit-learn:\n",
        "\n",
        "* Los pasos básicos para aplicar ML (análisis de datasets, cargado, preprocesado, entrenamiento, validación, optimización y persistencia)\n",
        "* Explorar el dataset\n",
        "* Visualizar el dataset\n",
        "* Aprender a cargar un bundle dataset\n",
        "* Separar el conjunto de datos en conjuntos de datos de prueba y de entrenamiento\n",
        "* Entrenar un clasificador\n",
        "* Predecir con un clasificador entrenado\n",
        "* Evaluar las predicciones\n",
        "* Optimizar la configuración del clasificador\n",
        "* Salvar el modelo\n",
        "\n"
      ],
      "metadata": {
        "id": "gk6qeO2Sw1rR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<font color='purple'>Leer el dataset</font>\n",
        "\n",
        "El dataset de dígitos se utiliza para clasificación. En este apartado exploramos los datos que tenemos para entender la información que nos aporta este conjunto de datos. \n",
        "\n",
        "Cada dígito (números del 0 al 9) está formado por 8x8 píxeles en el rango de 0 a 16. Con este conjunto de datos se intenta que el programa sea capaz de distinguir (clasificar) si un número es un 0, 1, 2, 3... \n",
        "\n"
      ],
      "metadata": {
        "id": "afGhVTGm1TCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PASOS PREVIOS\n",
        "# importar datasets de scikit-learn, cargar y mirar el tamaño \n",
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "print(digits.data.shape)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfJ12BStzIXG",
        "outputId": "b7d6cb37-9bbf-4403-a64d-fd37a0c06faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1797, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#El tipo es bunch (subtipo de diccionario)\n",
        "type(digits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwB12hPLz8_S",
        "outputId": "beabe3be-7b45-49a4-dd7e-ae9b539e388b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils.Bunch"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtenemos la descripción \n",
        "print(digits.DESCR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsx6-Ssa0E7A",
        "outputId": "3b43edde-45cc-48d5-ab45-964a835c38b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _digits_dataset:\n",
            "\n",
            "Optical recognition of handwritten digits dataset\n",
            "--------------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 1797\n",
            "    :Number of Attributes: 64\n",
            "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
            "    :Missing Attribute Values: None\n",
            "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
            "    :Date: July; 1998\n",
            "\n",
            "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
            "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
            "\n",
            "The data set contains images of hand-written digits: 10 classes where\n",
            "each class refers to a digit.\n",
            "\n",
            "Preprocessing programs made available by NIST were used to extract\n",
            "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
            "total of 43 people, 30 contributed to the training set and different 13\n",
            "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
            "4x4 and the number of on pixels are counted in each block. This generates\n",
            "an input matrix of 8x8 where each element is an integer in the range\n",
            "0..16. This reduces dimensionality and gives invariance to small\n",
            "distortions.\n",
            "\n",
            "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
            "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
            "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
            "1994.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
            "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
            "    Graduate Studies in Science and Engineering, Bogazici University.\n",
            "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
            "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
            "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
            "    Electrical and Electronic Engineering Nanyang Technological University.\n",
            "    2005.\n",
            "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
            "    Algorithm. NIPS. 2000.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Nombre de los atributos del dataset (son píxeles)\n",
        "#tenemos una matriz de 8x8 píxeles para cada dígito\n",
        "print(digits.feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vF7fdou0Ntc",
        "outputId": "61e605c6-8b8e-4ab1-efa7-cf5323c16ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Los atributos target. Son 10 clases (del número 0 al 9). \n",
        "print(digits.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch1eTLSB0tFR",
        "outputId": "1d0fc0fb-f130-486e-dd14-7a14cc778833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(digits.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fH2D1QazER5",
        "outputId": "607d031a-bedc-44ba-bf43-2fd1396f4dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#INSPECCIONAMOS\n",
        "\n",
        "print(digits.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81Ue2XjY1qBi",
        "outputId": "e7a30755-f318-4103-888d-335612a4fa6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.  0.  5. ...  0.  0.  0.]\n",
            " [ 0.  0.  0. ... 10.  0.  0.]\n",
            " [ 0.  0.  0. ... 16.  9.  0.]\n",
            " ...\n",
            " [ 0.  0.  1. ...  6.  0.  0.]\n",
            " [ 0.  0.  2. ... 12.  0.  0.]\n",
            " [ 0.  0. 10. ... 12.  1.  0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(digits.target)\n",
        "\n",
        "print(digits.data.shape)\n",
        "\n",
        "print(digits.data.ndim) #dimension 2\n",
        "\n",
        "print(digits.data.shape[0]) #1797 filas/muestras\n",
        "\n",
        "print(digits.data.shape[1]) #64 columnas\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKGDmtbt11bZ",
        "outputId": "3f908409-4ce4-48ed-8556-3708bce144ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 ... 8 9 8]\n",
            "(1797, 64)\n",
            "2\n",
            "1797\n",
            "64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<font color='purple'>Visualización y Exploración de los datos</font>\n",
        "\n",
        "El objetivo de este aparado es aprender a cómo analizar el dataset. Aquí se cubren tareas como **limpiar y cambiar el formato** de los datos"
      ],
      "metadata": {
        "id": "lkPw9Tdu3IXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#matplotlib para realizar las gráficas\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from pandas import DataFrame\n"
      ],
      "metadata": {
        "id": "27EvuOWihwGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#nos muestra un array muy largo\n",
        "print(digits.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0M4ZkUgh6wJ",
        "outputId": "af049388-0bb3-4353-b0b5-bb545e35b7d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.  0.  5. ...  0.  0.  0.]\n",
            " [ 0.  0.  0. ... 10.  0.  0.]\n",
            " [ 0.  0.  0. ... 16.  9.  0.]\n",
            " ...\n",
            " [ 0.  0.  1. ...  6.  0.  0.]\n",
            " [ 0.  0.  2. ... 12.  0.  0.]\n",
            " [ 0.  0. 10. ... 12.  1.  0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#nos muestra las clases en las que queremos clasificar los píxeles (0 ,1, 2, 3, 4, 5, 6, 7, 8, 9)\n",
        "print(digits.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQKCkjMRiK00",
        "outputId": "a224f1fe-2582-4cb9-a8f5-90d4ee173092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 ... 8 9 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#vemos como se representaría el dígito 0 \n",
        "print(\"Dígito 0:\\n\", digits.images[0])\n",
        "print(\"\\n\")\n",
        "#vemos como se representaría el dígito 8\n",
        "print(\"Dígito 8: \\n\", digits.images[8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOPpeFMYifhi",
        "outputId": "a3f6e052-784a-42f2-b165-9ffc16b2494d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dígito 0:\n",
            " [[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
            " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
            " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
            " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
            " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
            " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
            " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
            " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
            "\n",
            "\n",
            "Dígito 8: \n",
            " [[ 0.  0.  9. 14.  8.  1.  0.  0.]\n",
            " [ 0.  0. 12. 14. 14. 12.  0.  0.]\n",
            " [ 0.  0.  9. 10.  0. 15.  4.  0.]\n",
            " [ 0.  0.  3. 16. 12. 14.  2.  0.]\n",
            " [ 0.  0.  4. 16. 16.  2.  0.  0.]\n",
            " [ 0.  3. 16.  8. 10. 13.  2.  0.]\n",
            " [ 0.  1. 15.  1.  3. 16.  8.  0.]\n",
            " [ 0.  0. 11. 16. 15. 11.  1.  0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En Machine Learning vamos a querer transformar los datos siempre a números. Si pueden ser 0 y 1 mejor, si pueden ser datos positivos todavía mejor. Esto nos facilita la tarea de normalizar los datos."
      ],
      "metadata": {
        "id": "coEG95Zhi2kr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizar los datos en estructura de dataframe\n",
        "#Podemos ver el índice (del 0 al 1796) a la izquierda y a la derecha el dígito que representa cada ristra de píxeles\n",
        "digits_df = DataFrame(digits.data)\n",
        "digits_df.columns = digits.feature_names\n",
        "\n",
        "digits_df['species'] = digits.target\n",
        "\n",
        "#mostramos las 20 primeras filas\n",
        "digits_df.head(20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "id": "vBFDJWixiuY9",
        "outputId": "12b32b5d-5cb5-4f3b-cccb-82ddeb7dcd0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e527aa51-4a7b-45fc-8813-9dd513bc78d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel_0_0</th>\n",
              "      <th>pixel_0_1</th>\n",
              "      <th>pixel_0_2</th>\n",
              "      <th>pixel_0_3</th>\n",
              "      <th>pixel_0_4</th>\n",
              "      <th>pixel_0_5</th>\n",
              "      <th>pixel_0_6</th>\n",
              "      <th>pixel_0_7</th>\n",
              "      <th>pixel_1_0</th>\n",
              "      <th>pixel_1_1</th>\n",
              "      <th>pixel_1_2</th>\n",
              "      <th>pixel_1_3</th>\n",
              "      <th>pixel_1_4</th>\n",
              "      <th>pixel_1_5</th>\n",
              "      <th>pixel_1_6</th>\n",
              "      <th>pixel_1_7</th>\n",
              "      <th>pixel_2_0</th>\n",
              "      <th>pixel_2_1</th>\n",
              "      <th>pixel_2_2</th>\n",
              "      <th>pixel_2_3</th>\n",
              "      <th>pixel_2_4</th>\n",
              "      <th>pixel_2_5</th>\n",
              "      <th>pixel_2_6</th>\n",
              "      <th>pixel_2_7</th>\n",
              "      <th>pixel_3_0</th>\n",
              "      <th>pixel_3_1</th>\n",
              "      <th>pixel_3_2</th>\n",
              "      <th>pixel_3_3</th>\n",
              "      <th>pixel_3_4</th>\n",
              "      <th>pixel_3_5</th>\n",
              "      <th>pixel_3_6</th>\n",
              "      <th>pixel_3_7</th>\n",
              "      <th>pixel_4_0</th>\n",
              "      <th>pixel_4_1</th>\n",
              "      <th>pixel_4_2</th>\n",
              "      <th>pixel_4_3</th>\n",
              "      <th>pixel_4_4</th>\n",
              "      <th>pixel_4_5</th>\n",
              "      <th>pixel_4_6</th>\n",
              "      <th>pixel_4_7</th>\n",
              "      <th>pixel_5_0</th>\n",
              "      <th>pixel_5_1</th>\n",
              "      <th>pixel_5_2</th>\n",
              "      <th>pixel_5_3</th>\n",
              "      <th>pixel_5_4</th>\n",
              "      <th>pixel_5_5</th>\n",
              "      <th>pixel_5_6</th>\n",
              "      <th>pixel_5_7</th>\n",
              "      <th>pixel_6_0</th>\n",
              "      <th>pixel_6_1</th>\n",
              "      <th>pixel_6_2</th>\n",
              "      <th>pixel_6_3</th>\n",
              "      <th>pixel_6_4</th>\n",
              "      <th>pixel_6_5</th>\n",
              "      <th>pixel_6_6</th>\n",
              "      <th>pixel_6_7</th>\n",
              "      <th>pixel_7_0</th>\n",
              "      <th>pixel_7_1</th>\n",
              "      <th>pixel_7_2</th>\n",
              "      <th>pixel_7_3</th>\n",
              "      <th>pixel_7_4</th>\n",
              "      <th>pixel_7_5</th>\n",
              "      <th>pixel_7_6</th>\n",
              "      <th>pixel_7_7</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e527aa51-4a7b-45fc-8813-9dd513bc78d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e527aa51-4a7b-45fc-8813-9dd513bc78d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e527aa51-4a7b-45fc-8813-9dd513bc78d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    pixel_0_0  pixel_0_1  pixel_0_2  ...  pixel_7_6  pixel_7_7  species\n",
              "0         0.0        0.0        5.0  ...        0.0        0.0        0\n",
              "1         0.0        0.0        0.0  ...        0.0        0.0        1\n",
              "2         0.0        0.0        0.0  ...        9.0        0.0        2\n",
              "3         0.0        0.0        7.0  ...        0.0        0.0        3\n",
              "4         0.0        0.0        0.0  ...        0.0        0.0        4\n",
              "5         0.0        0.0       12.0  ...        0.0        0.0        5\n",
              "6         0.0        0.0        0.0  ...        3.0        0.0        6\n",
              "7         0.0        0.0        7.0  ...        0.0        0.0        7\n",
              "8         0.0        0.0        9.0  ...        1.0        0.0        8\n",
              "9         0.0        0.0       11.0  ...        0.0        0.0        9\n",
              "10        0.0        0.0        1.0  ...        0.0        0.0        0\n",
              "11        0.0        0.0        0.0  ...        1.0        0.0        1\n",
              "12        0.0        0.0        5.0  ...       12.0        4.0        2\n",
              "13        0.0        2.0        9.0  ...        0.0        0.0        3\n",
              "14        0.0        0.0        0.0  ...        0.0        0.0        4\n",
              "15        0.0        5.0       12.0  ...        0.0        0.0        5\n",
              "16        0.0        0.0        0.0  ...       11.0        0.0        6\n",
              "17        0.0        0.0        1.0  ...        0.0        0.0        7\n",
              "18        0.0        0.0       10.0  ...        0.0        0.0        8\n",
              "19        0.0        0.0        6.0  ...       11.0        1.0        9\n",
              "\n",
              "[20 rows x 65 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Podemos probar a mostrar como se verían algunos dígitos\n",
        "\n",
        "#La fila 0 y la 10 representan el 0. \n",
        "plt.imshow(digits.images[0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "plt.show()\n",
        "plt.imshow(digits.images[10], cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#La fila 5 y la 15 muestran el 5 (o eso creo)\n",
        "plt.imshow(digits.images[5], cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "plt.show()\n",
        "plt.imshow(digits.images[15], cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NU2XuNs0kr-j",
        "outputId": "b35ec033-bee3-435c-b584-92adae3fcf02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<font color='purple'>Preprocesado de los datos</font>\n",
        "\n",
        "Vamos a dividir los datos en dos grupos. El **training set** y el **test set**. Utilizamos el 75% del dataset para el entrenamiento y el 25% para el testing. Random_state nos asegura que el resultado siempre es el mismo y es reproducible, de otra manera tendríamos distintos entrenamientos y testeo cada vez.\n"
      ],
      "metadata": {
        "id": "Qp-iglYH3bSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_digits, y_digits = digits.data, digits.target\n",
        "# 25% para testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_digits, y_digits, test_size=0.25, random_state=33)"
      ],
      "metadata": {
        "id": "uMGoXZZ8BSQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dimensiones \n",
        "print(x_train.shape, x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJHsRwwXs4Nt",
        "outputId": "5d2dae3d-d363-40d5-d126-821bd64c764c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1347, 64) (450, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a9rO-b7Rd7U",
        "outputId": "96b11836-4f92-4c93-ffa0-15e320ea1e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1347,) (450,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test set\n",
        "print (x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvxO-TKus7Fh",
        "outputId": "81777ac8-63c1-4b7e-f1b9-40c31d6e8d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.  0.  4. ... 11.  0.  0.]\n",
            " [ 0.  0.  3. ... 16. 10.  0.]\n",
            " [ 0.  0.  7. ...  0.  0.  0.]\n",
            " ...\n",
            " [ 0.  0.  6. ... 12.  1.  0.]\n",
            " [ 0.  0.  0. ... 11.  1.  0.]\n",
            " [ 0.  0.  0. ... 16. 11.  0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train set\n",
        "print (x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_mhd9FWs_-F",
        "outputId": "f823e245-b472-4897-caf7-a39439855ea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.  0.  1. ...  0.  0.  0.]\n",
            " [ 0.  0.  4. ...  0.  0.  0.]\n",
            " [ 0.  0.  0. ...  0.  0.  0.]\n",
            " ...\n",
            " [ 0.  0.  4. ...  0.  0.  0.]\n",
            " [ 0.  0. 12. ...  0.  0.  0.]\n",
            " [ 0.  1.  7. ...  0.  0.  0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NORMALIZACIÓN\n",
        "\n",
        "from sklearn import preprocessing\n",
        "scaler = preprocessing.StandardScaler().fit(x_train)\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "iUeRALQCtHIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Podemos ver los datos normalizados\n",
        "print(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eJFESLctQnN",
        "outputId": "ef64efee-4183-4481-c345-851ad31e47f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.         -0.32672314 -0.2423893  ...  0.73926354 -0.49709493\n",
            "  -0.19054741]\n",
            " [ 0.         -0.32672314 -0.4534419  ...  1.58229435  1.97553015\n",
            "  -0.19054741]\n",
            " [ 0.         -0.32672314  0.39076852 ... -1.11540424 -0.49709493\n",
            "  -0.19054741]\n",
            " ...\n",
            " [ 0.         -0.32672314  0.17971592 ...  0.90786971 -0.24983242\n",
            "  -0.19054741]\n",
            " [ 0.         -0.32672314 -1.08659972 ...  0.73926354 -0.24983242\n",
            "  -0.19054741]\n",
            " [ 0.         -0.32672314 -1.08659972 ...  1.58229435  2.22279266\n",
            "  -0.19054741]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<font color='purple'>Algoritmos de CLASIFICACIÓN</font>"
      ],
      "metadata": {
        "id": "V0ugIRR6tvMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Algoritmo K-NN\n",
        "\n",
        "El método k-nearest neighbors es un método de clasificación supervisada que estima el valor de la función de densidad de probabilidad o directamente la probabilidad a posteriori de un elemento pertenezca a una clase. \n",
        "\n",
        "La función se aproxima solo localmente mediante ejemplos cercanos en el espacio de los elementos. \n",
        "\n"
      ],
      "metadata": {
        "id": "lvTzx16bA6QQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN MODEL\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Create kNN model\n",
        "model = KNeighborsClassifier(n_neighbors=15)\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(x_train, y_train) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jizMZH5tSXK",
        "outputId": "8c8012f0-c955-4877-e701-65e483b01f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=15)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prediction \", model.predict(x_train))\n",
        "print(\"Expected \", y_train)\n",
        "#Parece que hace buenas predicciones\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-Fdbn3qt3yW",
        "outputId": "4ba4822a-7b00-4fde-d78d-4946cbf3cea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction  [4 7 4 ... 1 5 5]\n",
            "Expected  [4 7 4 ... 1 5 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluación del algoritmo**\n",
        "\n",
        "*Precisión*: proporción de elementos predecidos como positivos que son evaluados correctamente (TP/FP+TP)\n",
        "\n",
        "*Recall*: cantidad de positivos que el modelo es capaz de identificar (TP/FN+TP).  \n",
        "\n",
        "*F-Score*: media armónica entre la precisión y el recall "
      ],
      "metadata": {
        "id": "aM4zHPEMpEg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Accuracy in training\n",
        "#Accuracy: porcentaje de casos que el modelo acierta (TP+TN/TP+TN+FN+FP)\n",
        "from sklearn import metrics\n",
        "y_train_pred = model.predict(x_train)\n",
        "print(\"Accuracy in training\", metrics.accuracy_score(y_train, y_train_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNYcAl8BHaqa",
        "outputId": "64676786-be93-42bd-9a22-8dc3f27d8b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy in training 0.9732739420935412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we evaluate error in testing\n",
        "#Tenemos una accuracy bastante decente\n",
        "\n",
        "y_test_pred = model.predict(x_test)\n",
        "print(\"Accuracy in testing \", metrics.accuracy_score(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSY1J3KEHdKp",
        "outputId": "d7ff29da-8148-4fa6-a336-e6d919d90893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy in testing  0.9711111111111111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KFOLD VALIDATION\n",
        "\n",
        "#La validación cruzada o cross-validation es una técnica utilizada para evaluar \n",
        "#los resultados de un análisis estadístico y garantizar que son independientes \n",
        "#de la partición entre datos de entrenamiento y prueba.\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# create a composite estimator made by a pipeline of preprocessing and the KNN model\n",
        "model = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('kNN', KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "# create a k-fold cross validation iterator of k=10 folds\n",
        "cv = KFold(10, shuffle=True, random_state=33)\n",
        "\n",
        "# by default the score used is the one returned by score method of the estimator (accuracy)\n",
        "scores = cross_val_score(model, x_digits, y_digits, cv=cv)\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PerVvMcksAnT",
        "outputId": "30321e06-4c6b-436d-ddaf-a1b282c33030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.97777778 0.97222222 0.99444444 0.97777778 0.97222222 0.96111111\n",
            " 0.97777778 0.97765363 0.98882682 0.98882682]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#La media de la precisión/accuracy es 0.979, es un buen resultado.\n",
        "from scipy.stats import sem\n",
        "def mean_score(scores):\n",
        "    return (\"Mean score: {0:.3f} (+/- {1:.3f})\").format(np.mean(scores), sem(scores))\n",
        "print(mean_score(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prs-LEbOsLUx",
        "outputId": "982c9335-1c08-4585-af0f-fc4b6c338c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean score: 0.979 (+/- 0.003)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cambiar el número de vecinos**"
      ],
      "metadata": {
        "id": "kzXDMBOfIrCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_range = range(1, 21)\n",
        "accuracy = []\n",
        "for k in k_range:\n",
        "    m = KNeighborsClassifier(k)\n",
        "    m.fit(x_train, y_train)\n",
        "    y_test_pred = m.predict(x_test)\n",
        "    accuracy.append(metrics.accuracy_score(y_test, y_test_pred))\n",
        "plt.plot(k_range, accuracy)\n",
        "plt.xlabel('k value')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "#tal y como se aprecia para k=4 podríamos obtener una accuracy de 0.976 aproximadamente"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "5xacf9AYsVMR",
        "outputId": "2d5e8505-7a88-4483-8557-a8ee0f00d717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#probamos con k=4\n",
        "# Create kNN model\n",
        "model = KNeighborsClassifier(n_neighbors=4)\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(x_train, y_train) \n",
        "y_train_pred = model.predict(x_train)\n",
        "print(\"Accuracy in training\", metrics.accuracy_score(y_train, y_train_pred))\n",
        "y_test_pred = model.predict(x_test)\n",
        "print(\"Accuracy in testing \", metrics.accuracy_score(y_test, y_test_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFk1718nJ8HA",
        "outputId": "e4f4ad08-c83f-46e7-dbee-89ee5c77792a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy in training 0.9821826280623608\n",
            "Accuracy in testing  0.9688888888888889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KFOLD VALIDATION\n",
        "#Para k=5\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# create a composite estimator made by a pipeline of preprocessing and the KNN model\n",
        "model = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('kNN', KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "# create a k-fold cross validation iterator of k=5 folds\n",
        "cv = KFold(4, shuffle=True, random_state=33)\n",
        "\n",
        "# by default the score used is the one returned by score method of the estimator (accuracy)\n",
        "scores = cross_val_score(model, x_digits, y_digits, cv=cv)\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JE5UC8iHI5yK",
        "outputId": "276ac2d5-9b90-4323-8fb2-9fa3dc083e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.97555556 0.97995546 0.9688196  0.97772829]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import sem\n",
        "def mean_score(scores):\n",
        "    return (\"Mean score: {0:.3f} (+/- {1:.3f})\").format(np.mean(scores), sem(scores))\n",
        "print(mean_score(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_du8aEP5bQ77",
        "outputId": "79281ade-4e1b-4e38-f283-e246906cbd1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean score: 0.976 (+/- 0.002)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algoritmo Árbol de decisión\n",
        "\n",
        " Dado un conjunto de datos se fabrican diagramas de construcciones lógicas, muy similares a los sistemas de predicción basados en reglas, que sirven para representar y categorizar una serie de condiciones que ocurren de forma sucesiva, para la resolución de un problema."
      ],
      "metadata": {
        "id": "hWZXs0SbLDvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import tree\n",
        "\n",
        "max_depth=3 #número de preguntas a los datos\n",
        "random_state=1 \n",
        "\n",
        "# Create decision tree model\n",
        "model = tree.DecisionTreeClassifier(max_depth=max_depth, random_state=random_state)\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(x_train, y_train) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvB3MK8BLNQE",
        "outputId": "69fe98b1-3998-4e04-913a-44d819b34f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(max_depth=3, random_state=1)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prediction \", model.predict(x_train))\n",
        "print(\"Expected \", y_train)\n",
        "#Podemos ver un error de predicción en los últimos números "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHPX1gsZLykV",
        "outputId": "b74be720-1405-4813-b5ca-6575dc45f440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction  [4 7 4 ... 3 3 5]\n",
            "Expected  [4 7 4 ... 1 5 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the \n",
        "print(\"Predicted probabilities\", model.predict_proba(x_train[:10]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-7-m6GQMhus",
        "outputId": "f96fb769-6100-44d8-bcf5-d59ed97bcc8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted probabilities [[0.01123596 0.10674157 0.         0.00842697 0.33707865 0.08707865\n",
            "  0.33707865 0.00842697 0.07303371 0.03089888]\n",
            " [0.         0.04591837 0.0255102  0.03571429 0.10204082 0.01530612\n",
            "  0.         0.67346939 0.04081633 0.06122449]\n",
            " [0.01123596 0.10674157 0.         0.00842697 0.33707865 0.08707865\n",
            "  0.33707865 0.00842697 0.07303371 0.03089888]\n",
            " [0.         0.04591837 0.0255102  0.03571429 0.10204082 0.01530612\n",
            "  0.         0.67346939 0.04081633 0.06122449]\n",
            " [0.01123596 0.10674157 0.         0.00842697 0.33707865 0.08707865\n",
            "  0.33707865 0.00842697 0.07303371 0.03089888]\n",
            " [0.95862069 0.         0.         0.         0.02758621 0.00689655\n",
            "  0.00689655 0.         0.         0.        ]\n",
            " [0.95862069 0.         0.         0.         0.02758621 0.00689655\n",
            "  0.00689655 0.         0.         0.        ]\n",
            " [0.         0.15083799 0.23277467 0.23649907 0.0018622  0.07635009\n",
            "  0.01303538 0.00931099 0.14897579 0.13035382]\n",
            " [0.         0.15083799 0.23277467 0.23649907 0.0018622  0.07635009\n",
            "  0.01303538 0.00931099 0.14897579 0.13035382]\n",
            " [0.         0.04591837 0.0255102  0.03571429 0.10204082 0.01530612\n",
            "  0.         0.67346939 0.04081633 0.06122449]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Accuracy in training\n",
        "\n",
        "from sklearn import metrics\n",
        "y_train_pred = model.predict(x_train)\n",
        "print(\"Accuracy in training\", metrics.accuracy_score(y_train, y_train_pred))\n",
        "#Accuracy muy mala"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQMu0VSYMlUq",
        "outputId": "fe8bffed-9cdf-4f3a-af83-abb0eb1da439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy in training 0.45879732739420936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we evaluate error in testing\n",
        "y_test_pred = model.predict(x_test)\n",
        "print(\"Accuracy in testing \", metrics.accuracy_score(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skHxECxHMpZl",
        "outputId": "15fac0df-57b9-4a5b-edc0-c8c6ef0e8171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy in testing  0.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluación del algoritmo**"
      ],
      "metadata": {
        "id": "pl1FO5HNNMyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#K-FOLD CROSS VALIDATION\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# create a composite estimator made by a pipeline of preprocessing and the KNN model\n",
        "model = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('DecisionTree', DecisionTreeClassifier())\n",
        "])\n",
        "\n",
        "# create a k-fold cross validation iterator of k=10 folds\n",
        "cv = KFold(10, shuffle=True, random_state=33)\n",
        "\n",
        "# by default the score used is the one returned by score method of the estimator (accuracy)\n",
        "scores = cross_val_score(model, x_digits, y_digits, cv=cv)\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZYBqsNnM-ik",
        "outputId": "95387ad4-0e68-4079-dae6-48a01fd28845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.83888889 0.81111111 0.83888889 0.88333333 0.89444444 0.84444444\n",
            " 0.87777778 0.87150838 0.8547486  0.82681564]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import sem\n",
        "def mean_score(scores):\n",
        "    return (\"Mean score: {0:.3f} (+/- {1:.3f})\").format(np.mean(scores), sem(scores))\n",
        "print(mean_score(scores))\n",
        "#Podemos ver que este modelo con estos parámetros de entrada da un resultado mejorable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGaCJLIZNVKX",
        "outputId": "b5d9e62d-5ede-45d8-87b8-56787a579688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean score: 0.854 (+/- 0.008)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mejora del algoritmo**\n",
        "\n",
        "A la vista de los resultados tan pobres que nos aporta el árbol de decisión, vamos a intentar customizarlo para mejorar la predicción. \n",
        "Tal y como se ve en la caja de código anterior se obtiene una mean score en la precisión de 0.854"
      ],
      "metadata": {
        "id": "W1AbiCdwaDk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "\n",
        "# create a composite estimator made by a pipeline of preprocessing and the KNN model\n",
        "model = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('ds', DecisionTreeClassifier())\n",
        "])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(x_train, y_train) \n",
        "\n",
        "# create a k-fold cross validation iterator of k=10 folds\n",
        "cv = KFold(10, shuffle=True, random_state=33)\n",
        "\n",
        "# by default the score used is the one returned by score method of the estimator (accuracy)\n",
        "scores = cross_val_score(model, x_digits, y_digits, cv=cv)\n",
        "\n",
        "from scipy.stats import sem\n",
        "def mean_score(scores):\n",
        "    return (\"Mean score: {0:.3f} (+/- {1:.3f})\").format(np.mean(scores), sem(scores))\n",
        "print(mean_score(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1A73Rc3bDWT",
        "outputId": "8441f903-3a91-4293-8784-d228b9798447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean score: 0.859 (+/- 0.004)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipelines\n",
        "model.named_steps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIkAcnHlc3La",
        "outputId": "1ceb18aa-56d1-4e03-fdd4-767bb8848eae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ds': DecisionTreeClassifier(), 'scaler': StandardScaler()}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.steps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEQ7TH27c6Qc",
        "outputId": "158aca59-6df3-4d62-c717-78c9f0cf2607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('scaler', StandardScaler()), ('ds', DecisionTreeClassifier())]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_params().keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a83jYaQbc8mD",
        "outputId": "5ac33011-3430-4cd9-fcd1-ee271e2be46d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['memory', 'steps', 'verbose', 'scaler', 'ds', 'scaler__copy', 'scaler__with_mean', 'scaler__with_std', 'ds__ccp_alpha', 'ds__class_weight', 'ds__criterion', 'ds__max_depth', 'ds__max_features', 'ds__max_leaf_nodes', 'ds__min_impurity_decrease', 'ds__min_samples_leaf', 'ds__min_samples_split', 'ds__min_weight_fraction_leaf', 'ds__random_state', 'ds__splitter'])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.set_params(ds__class_weight='balanced')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAJ4pxnDc9it",
        "outputId": "debb0bd8-48d6-4b03-9293-4c876621a947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('ds', DecisionTreeClassifier(class_weight='balanced'))])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('ds', DecisionTreeClassifier(class_weight='balanced'))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWA2NpuRdBPD",
        "outputId": "e145e4ca-8706-446b-abfe-c9793a7179c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('ds', DecisionTreeClassifier(class_weight='balanced'))])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model.fit(x_train, y_train) \n",
        "# Using named_steps\n",
        "my_decision_tree = model.named_steps['ds']\n",
        "print(my_decision_tree.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdcQlcGJdC2k",
        "outputId": "3c346bda-e837-4837-d029-32f6f0e2ef8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.         0.         0.0184348  0.00286825 0.02364504 0.04552484\n",
            " 0.00164574 0.         0.         0.00872439 0.01728758 0.00308886\n",
            " 0.01126655 0.01598772 0.00137457 0.         0.         0.00461815\n",
            " 0.01233964 0.02629468 0.04658112 0.08232796 0.00084524 0.\n",
            " 0.00150876 0.0039439  0.01976661 0.06266703 0.00511314 0.0473036\n",
            " 0.00105319 0.         0.         0.05970697 0.01028098 0.00082305\n",
            " 0.07396948 0.03415562 0.0120311  0.         0.         0.00229761\n",
            " 0.11377921 0.06403012 0.0118482  0.00418259 0.0061059  0.\n",
            " 0.         0.00368624 0.00431456 0.00776765 0.00550506 0.01890021\n",
            " 0.02525985 0.         0.         0.         0.00806131 0.\n",
            " 0.06233126 0.00395893 0.00279274 0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using steps, we take the last step (-1) or the second step (1)\n",
        "#name, my_desision_tree = model.steps[1]\n",
        "name, my_desision_tree = model.steps[-1]\n",
        "print(my_decision_tree.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toNJwkcldESL",
        "outputId": "5ee7df21-1c67-407d-a934-c201c5f408e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.         0.         0.0184348  0.00286825 0.02364504 0.04552484\n",
            " 0.00164574 0.         0.         0.00872439 0.01728758 0.00308886\n",
            " 0.01126655 0.01598772 0.00137457 0.         0.         0.00461815\n",
            " 0.01233964 0.02629468 0.04658112 0.08232796 0.00084524 0.\n",
            " 0.00150876 0.0039439  0.01976661 0.06266703 0.00511314 0.0473036\n",
            " 0.00105319 0.         0.         0.05970697 0.01028098 0.00082305\n",
            " 0.07396948 0.03415562 0.0120311  0.         0.         0.00229761\n",
            " 0.11377921 0.06403012 0.0118482  0.00418259 0.0061059  0.\n",
            " 0.         0.00368624 0.00431456 0.00776765 0.00550506 0.01890021\n",
            " 0.02525985 0.         0.         0.         0.00806131 0.\n",
            " 0.06233126 0.00395893 0.00279274 0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EMPEZAMOS CON EL TUNING\n",
        "model.get_params()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ILw3EIqdF-z",
        "outputId": "3cac07f5-a8fb-4566-9dd1-98c2bcfabbda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ds': DecisionTreeClassifier(class_weight='balanced'),\n",
              " 'ds__ccp_alpha': 0.0,\n",
              " 'ds__class_weight': 'balanced',\n",
              " 'ds__criterion': 'gini',\n",
              " 'ds__max_depth': None,\n",
              " 'ds__max_features': None,\n",
              " 'ds__max_leaf_nodes': None,\n",
              " 'ds__min_impurity_decrease': 0.0,\n",
              " 'ds__min_samples_leaf': 1,\n",
              " 'ds__min_samples_split': 2,\n",
              " 'ds__min_weight_fraction_leaf': 0.0,\n",
              " 'ds__random_state': None,\n",
              " 'ds__splitter': 'best',\n",
              " 'memory': None,\n",
              " 'scaler': StandardScaler(),\n",
              " 'scaler__copy': True,\n",
              " 'scaler__with_mean': True,\n",
              " 'scaler__with_std': True,\n",
              " 'steps': [('scaler', StandardScaler()),\n",
              "  ('ds', DecisionTreeClassifier(class_weight='balanced'))],\n",
              " 'verbose': False}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Grid search for Parameter optimization**\n",
        "\n",
        "The sklearn provides an object that, given data, computes the score during the fit of an estimator on a parameter grid and chooses the parameters to maximize the cross-validation score. "
      ],
      "metadata": {
        "id": "aLbuP_T6LZyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "\n",
        "param_grid = {'max_depth': np.arange(3, 10)} \n",
        "\n",
        "gs = GridSearchCV(DecisionTreeClassifier(), param_grid)\n",
        "\n",
        "gs.fit(x_train, y_train)\n",
        "\n",
        "# summarize the results of the grid search\n",
        "print(\"Best score: \", gs.best_score_)\n",
        "print(\"Best params: \", gs.best_params_)\n",
        "\n",
        "#Obtenemos un max_depth óptima de 9\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITiGIczQdKru",
        "outputId": "e543fbdd-0492-44ca-bf72-e336f6c55b1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score:  0.8284648216990224\n",
            "Best params:  {'max_depth': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We print the score for each value of max_depth\n",
        "for i, max_depth in enumerate(gs.cv_results_['params']):\n",
        "    print(\"%0.3f (+/-%0.03f) for %r\" % (gs.cv_results_['mean_test_score'][i],\n",
        "                                        gs.cv_results_['std_test_score'][i] * 2,\n",
        "                                        max_depth))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr1hkbjZdSQm",
        "outputId": "a11a8dbc-08c4-45ad-c21c-fd82cd839100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.444 (+/-0.054) for {'max_depth': 3}\n",
            "0.592 (+/-0.094) for {'max_depth': 4}\n",
            "0.673 (+/-0.043) for {'max_depth': 5}\n",
            "0.768 (+/-0.038) for {'max_depth': 6}\n",
            "0.796 (+/-0.067) for {'max_depth': 7}\n",
            "0.821 (+/-0.043) for {'max_depth': 8}\n",
            "0.828 (+/-0.056) for {'max_depth': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a composite estimator made by a pipeline of preprocessing and the KNN model\n",
        "model = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('ds', DecisionTreeClassifier(max_depth=9))\n",
        "])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(x_train, y_train) \n",
        "\n",
        "# create a k-fold cross validation iterator of k=10 folds\n",
        "cv = KFold(10, shuffle=True, random_state=33)\n",
        "\n",
        "# by default the score used is the one returned by score method of the estimator (accuracy)\n",
        "scores = cross_val_score(model, x_digits, y_digits, cv=cv)\n",
        "def mean_score(scores):\n",
        "    return (\"Mean score: {0:.3f} (+/- {1:.3f})\").format(np.mean(scores), sem(scores))\n",
        "print(mean_score(scores))\n",
        "\n",
        "#No veo que se produzca una mejora "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orVtBdJjdU_s",
        "outputId": "6f7f01ae-87f1-4f7b-c695-a41bbe6369a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean score: 0.854 (+/- 0.007)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the parameters by cross-validation\n",
        "\n",
        "from sklearn.metrics import classification_report, recall_score, precision_score, make_scorer\n",
        "\n",
        "# set of parameters to test\n",
        "tuned_parameters = [{'max_depth': np.arange(3, 10),\n",
        "#                     'max_weights': [1, 10, 100, 1000]},\n",
        "                     'criterion': ['gini', 'entropy'], \n",
        "                     'splitter': ['best', 'random'],\n",
        "                    # 'min_samples_leaf': [2, 5, 10],\n",
        "                     'class_weight':['balanced', None],\n",
        "                     'max_leaf_nodes': [None, 5, 10, 20]\n",
        "                    }]\n",
        "\n",
        "scores = ['precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "\n",
        "    if score == 'precision':\n",
        "        scorer = make_scorer(precision_score, average='weighted', zero_division=0)\n",
        "    elif score == 'recall':\n",
        "        scorer = make_scorer(recall_score, average='weighted', zero_division=0)\n",
        "    \n",
        "    # cv = the fold of the cross-validation cv, defaulted to 5\n",
        "    gs = GridSearchCV(DecisionTreeClassifier(), tuned_parameters, cv=10, scoring=scorer)\n",
        "    gs.fit(x_train, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(gs.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = gs.cv_results_['mean_test_score']\n",
        "    stds = gs.cv_results_['std_test_score']\n",
        "\n",
        "    for mean_score, std_score, params in zip(means, stds, gs.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean_score, std_score * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    y_true, y_pred = y_test, gs.predict(x_test)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0ai-ISMdb7e",
        "outputId": "a9894581-0a3a-4a00-e26a-29f16b98675f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Tuning hyper-parameters for precision\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.416 (+/-0.042) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.462 (+/-0.137) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.288 (+/-0.032) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.280 (+/-0.038) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.416 (+/-0.042) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.431 (+/-0.119) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.416 (+/-0.042) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.424 (+/-0.099) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.584 (+/-0.035) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.608 (+/-0.095) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.288 (+/-0.032) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.278 (+/-0.047) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.562 (+/-0.059) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.592 (+/-0.140) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.587 (+/-0.038) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.659 (+/-0.167) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.768 (+/-0.058) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.744 (+/-0.050) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.288 (+/-0.032) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.267 (+/-0.044) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.618 (+/-0.055) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.624 (+/-0.128) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.769 (+/-0.055) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.712 (+/-0.113) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.821 (+/-0.037) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.772 (+/-0.090) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.288 (+/-0.032) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.273 (+/-0.054) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.643 (+/-0.055) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.649 (+/-0.113) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.797 (+/-0.041) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.758 (+/-0.062) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.834 (+/-0.069) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.807 (+/-0.063) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.288 (+/-0.032) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.272 (+/-0.045) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.643 (+/-0.055) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.634 (+/-0.103) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.815 (+/-0.052) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.758 (+/-0.076) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.846 (+/-0.053) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.851 (+/-0.052) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.288 (+/-0.032) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.301 (+/-0.049) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.643 (+/-0.055) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.612 (+/-0.101) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.814 (+/-0.057) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.760 (+/-0.061) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.865 (+/-0.053) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.860 (+/-0.044) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.288 (+/-0.032) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.277 (+/-0.071) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.643 (+/-0.055) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.621 (+/-0.115) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.814 (+/-0.057) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.754 (+/-0.076) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.500 (+/-0.100) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.392 (+/-0.112) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.277 (+/-0.032) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.232 (+/-0.041) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.500 (+/-0.100) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.441 (+/-0.064) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.500 (+/-0.100) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.408 (+/-0.107) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.689 (+/-0.057) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.626 (+/-0.096) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.277 (+/-0.032) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.228 (+/-0.075) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.640 (+/-0.073) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.578 (+/-0.128) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.689 (+/-0.057) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.643 (+/-0.117) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.788 (+/-0.041) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.746 (+/-0.080) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.277 (+/-0.032) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.237 (+/-0.068) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.666 (+/-0.132) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.597 (+/-0.108) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.786 (+/-0.053) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.720 (+/-0.086) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.825 (+/-0.038) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.794 (+/-0.065) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.277 (+/-0.032) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.239 (+/-0.041) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.666 (+/-0.132) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.572 (+/-0.126) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.797 (+/-0.067) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.758 (+/-0.072) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.844 (+/-0.041) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.824 (+/-0.053) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.277 (+/-0.032) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.236 (+/-0.056) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.666 (+/-0.132) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.571 (+/-0.149) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.798 (+/-0.068) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.738 (+/-0.043) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.844 (+/-0.043) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.856 (+/-0.057) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.277 (+/-0.032) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.230 (+/-0.061) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.666 (+/-0.132) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.551 (+/-0.124) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.798 (+/-0.068) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.739 (+/-0.080) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.852 (+/-0.043) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.841 (+/-0.041) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.277 (+/-0.032) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.234 (+/-0.063) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.666 (+/-0.132) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.542 (+/-0.093) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.798 (+/-0.068) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.757 (+/-0.059) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.413 (+/-0.066) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.456 (+/-0.129) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.291 (+/-0.059) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.276 (+/-0.060) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.413 (+/-0.066) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.432 (+/-0.170) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.413 (+/-0.066) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.434 (+/-0.121) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.595 (+/-0.036) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.613 (+/-0.089) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.290 (+/-0.031) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.259 (+/-0.046) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.574 (+/-0.049) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.581 (+/-0.137) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.591 (+/-0.051) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.604 (+/-0.129) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.724 (+/-0.076) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.719 (+/-0.107) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.290 (+/-0.031) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.285 (+/-0.042) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.622 (+/-0.070) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.595 (+/-0.119) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.715 (+/-0.076) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.754 (+/-0.086) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.793 (+/-0.040) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.772 (+/-0.086) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.290 (+/-0.031) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.261 (+/-0.050) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.637 (+/-0.049) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.601 (+/-0.123) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.772 (+/-0.049) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.743 (+/-0.084) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.809 (+/-0.080) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.815 (+/-0.048) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.290 (+/-0.031) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.263 (+/-0.047) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.637 (+/-0.049) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.608 (+/-0.062) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.781 (+/-0.074) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.756 (+/-0.048) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.835 (+/-0.059) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.824 (+/-0.062) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.290 (+/-0.031) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.268 (+/-0.066) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.637 (+/-0.049) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.593 (+/-0.072) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.784 (+/-0.065) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.722 (+/-0.097) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.848 (+/-0.030) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.860 (+/-0.048) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.290 (+/-0.031) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.286 (+/-0.038) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.637 (+/-0.049) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.599 (+/-0.067) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.784 (+/-0.065) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.753 (+/-0.088) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.502 (+/-0.092) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.436 (+/-0.104) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.278 (+/-0.032) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.238 (+/-0.045) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.502 (+/-0.092) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.429 (+/-0.133) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.502 (+/-0.092) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.466 (+/-0.125) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.688 (+/-0.059) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.643 (+/-0.080) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.278 (+/-0.032) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.235 (+/-0.050) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.638 (+/-0.076) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.556 (+/-0.076) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.687 (+/-0.059) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.657 (+/-0.155) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.771 (+/-0.049) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.764 (+/-0.088) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.278 (+/-0.032) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.236 (+/-0.062) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.651 (+/-0.107) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.564 (+/-0.082) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.767 (+/-0.061) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.746 (+/-0.079) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.823 (+/-0.041) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.810 (+/-0.062) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.278 (+/-0.032) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.230 (+/-0.040) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.651 (+/-0.107) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.595 (+/-0.103) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.784 (+/-0.072) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.737 (+/-0.082) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.844 (+/-0.037) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.815 (+/-0.070) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.278 (+/-0.032) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.256 (+/-0.058) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.651 (+/-0.107) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.582 (+/-0.123) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.784 (+/-0.072) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.729 (+/-0.076) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.850 (+/-0.056) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.839 (+/-0.029) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.278 (+/-0.032) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.234 (+/-0.052) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.651 (+/-0.107) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.572 (+/-0.111) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.784 (+/-0.072) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.726 (+/-0.115) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.852 (+/-0.053) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.848 (+/-0.058) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.278 (+/-0.032) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.239 (+/-0.033) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.651 (+/-0.107) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.562 (+/-0.097) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.784 (+/-0.072) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.730 (+/-0.083) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97        35\n",
            "           1       0.70      0.87      0.78        54\n",
            "           2       0.88      0.82      0.85        44\n",
            "           3       0.84      0.80      0.82        46\n",
            "           4       0.86      0.86      0.86        35\n",
            "           5       0.90      0.90      0.90        48\n",
            "           6       0.92      0.94      0.93        51\n",
            "           7       0.79      0.89      0.84        35\n",
            "           8       0.85      0.67      0.75        58\n",
            "           9       0.74      0.73      0.74        44\n",
            "\n",
            "    accuracy                           0.84       450\n",
            "   macro avg       0.85      0.84      0.84       450\n",
            "weighted avg       0.84      0.84      0.84       450\n",
            "\n",
            "\n",
            "# Tuning hyper-parameters for recall\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.471 (+/-0.040) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.515 (+/-0.109) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.431 (+/-0.036) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.420 (+/-0.046) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.471 (+/-0.040) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.481 (+/-0.058) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.471 (+/-0.040) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.488 (+/-0.081) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.574 (+/-0.041) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.615 (+/-0.081) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.431 (+/-0.036) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.435 (+/-0.026) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.561 (+/-0.048) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.604 (+/-0.112) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.572 (+/-0.042) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.618 (+/-0.088) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.696 (+/-0.080) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.694 (+/-0.095) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.431 (+/-0.036) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.425 (+/-0.056) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.633 (+/-0.053) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.618 (+/-0.068) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.696 (+/-0.083) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.658 (+/-0.156) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.786 (+/-0.051) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.758 (+/-0.095) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.431 (+/-0.036) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.414 (+/-0.067) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.666 (+/-0.041) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.636 (+/-0.076) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.771 (+/-0.055) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.725 (+/-0.077) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.828 (+/-0.087) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.798 (+/-0.079) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.431 (+/-0.036) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.429 (+/-0.031) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.666 (+/-0.041) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.595 (+/-0.067) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.800 (+/-0.062) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.726 (+/-0.095) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.843 (+/-0.060) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.840 (+/-0.036) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.431 (+/-0.036) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.434 (+/-0.044) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.666 (+/-0.041) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.616 (+/-0.074) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.801 (+/-0.062) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.728 (+/-0.081) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.861 (+/-0.052) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.838 (+/-0.050) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.431 (+/-0.036) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.402 (+/-0.041) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.666 (+/-0.041) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.647 (+/-0.055) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.801 (+/-0.062) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.731 (+/-0.058) for {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.581 (+/-0.047) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.514 (+/-0.080) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.462 (+/-0.039) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.396 (+/-0.094) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.581 (+/-0.047) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.513 (+/-0.062) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.581 (+/-0.047) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.525 (+/-0.048) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.700 (+/-0.043) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.646 (+/-0.077) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.462 (+/-0.039) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.418 (+/-0.047) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.661 (+/-0.063) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.609 (+/-0.088) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.701 (+/-0.043) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.646 (+/-0.076) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.768 (+/-0.043) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.737 (+/-0.048) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.462 (+/-0.039) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.423 (+/-0.047) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.667 (+/-0.080) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.624 (+/-0.054) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.768 (+/-0.052) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.705 (+/-0.106) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.803 (+/-0.048) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.803 (+/-0.057) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.462 (+/-0.039) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.415 (+/-0.047) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.667 (+/-0.080) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.618 (+/-0.045) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.778 (+/-0.073) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.722 (+/-0.082) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.834 (+/-0.037) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.825 (+/-0.077) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.462 (+/-0.039) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.407 (+/-0.053) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.667 (+/-0.080) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.585 (+/-0.099) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.780 (+/-0.074) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.726 (+/-0.078) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.843 (+/-0.057) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.849 (+/-0.054) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.462 (+/-0.039) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.404 (+/-0.029) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.667 (+/-0.080) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.612 (+/-0.091) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.780 (+/-0.074) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.721 (+/-0.103) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.850 (+/-0.049) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.849 (+/-0.078) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.462 (+/-0.039) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.412 (+/-0.077) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.667 (+/-0.080) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.602 (+/-0.109) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.780 (+/-0.074) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.724 (+/-0.053) for {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.439 (+/-0.041) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.494 (+/-0.082) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.406 (+/-0.043) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.414 (+/-0.058) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.439 (+/-0.041) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.507 (+/-0.098) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.439 (+/-0.041) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.508 (+/-0.089) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.599 (+/-0.049) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.609 (+/-0.068) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.441 (+/-0.036) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.421 (+/-0.044) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.590 (+/-0.053) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.589 (+/-0.089) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.597 (+/-0.049) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.653 (+/-0.161) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.689 (+/-0.080) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.712 (+/-0.112) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.441 (+/-0.036) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.434 (+/-0.056) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.643 (+/-0.056) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.608 (+/-0.048) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.689 (+/-0.082) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.699 (+/-0.082) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.772 (+/-0.063) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.754 (+/-0.079) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.441 (+/-0.036) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.424 (+/-0.046) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.652 (+/-0.053) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.613 (+/-0.050) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.753 (+/-0.064) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.731 (+/-0.075) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.798 (+/-0.086) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.802 (+/-0.064) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.441 (+/-0.036) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.419 (+/-0.058) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.652 (+/-0.053) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.584 (+/-0.069) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.770 (+/-0.074) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.727 (+/-0.068) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.812 (+/-0.032) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.817 (+/-0.059) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.441 (+/-0.036) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.425 (+/-0.049) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.652 (+/-0.053) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.610 (+/-0.061) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.773 (+/-0.064) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.730 (+/-0.070) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.834 (+/-0.031) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.840 (+/-0.054) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.441 (+/-0.036) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.411 (+/-0.069) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.652 (+/-0.053) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.615 (+/-0.084) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.773 (+/-0.064) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.731 (+/-0.073) for {'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.583 (+/-0.050) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.513 (+/-0.076) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.463 (+/-0.039) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.405 (+/-0.052) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.583 (+/-0.050) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.510 (+/-0.105) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.583 (+/-0.050) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.537 (+/-0.090) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.699 (+/-0.055) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.655 (+/-0.106) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.463 (+/-0.039) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.415 (+/-0.064) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.660 (+/-0.067) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.587 (+/-0.088) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.701 (+/-0.054) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.667 (+/-0.083) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.756 (+/-0.042) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.731 (+/-0.089) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.463 (+/-0.039) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.418 (+/-0.042) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.660 (+/-0.067) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.619 (+/-0.085) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.756 (+/-0.047) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.708 (+/-0.051) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.798 (+/-0.043) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.809 (+/-0.118) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.463 (+/-0.039) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.410 (+/-0.064) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.660 (+/-0.067) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.607 (+/-0.087) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.768 (+/-0.057) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.732 (+/-0.060) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.840 (+/-0.036) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.817 (+/-0.053) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.463 (+/-0.039) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.402 (+/-0.055) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.660 (+/-0.067) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.599 (+/-0.111) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.768 (+/-0.057) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.704 (+/-0.073) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.843 (+/-0.047) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.839 (+/-0.049) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.463 (+/-0.039) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.410 (+/-0.049) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.660 (+/-0.067) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.598 (+/-0.100) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.768 (+/-0.057) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.701 (+/-0.062) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "0.843 (+/-0.050) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': None, 'splitter': 'best'}\n",
            "0.844 (+/-0.048) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
            "0.463 (+/-0.039) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 5, 'splitter': 'best'}\n",
            "0.400 (+/-0.063) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 5, 'splitter': 'random'}\n",
            "0.660 (+/-0.067) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 10, 'splitter': 'best'}\n",
            "0.594 (+/-0.050) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
            "0.768 (+/-0.057) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 20, 'splitter': 'best'}\n",
            "0.736 (+/-0.065) for {'class_weight': None, 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 20, 'splitter': 'random'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97        35\n",
            "           1       0.68      0.87      0.76        54\n",
            "           2       0.82      0.75      0.79        44\n",
            "           3       0.81      0.76      0.79        46\n",
            "           4       0.86      0.86      0.86        35\n",
            "           5       0.86      0.88      0.87        48\n",
            "           6       0.96      0.94      0.95        51\n",
            "           7       0.78      0.89      0.83        35\n",
            "           8       0.80      0.64      0.71        58\n",
            "           9       0.72      0.70      0.71        44\n",
            "\n",
            "    accuracy                           0.82       450\n",
            "   macro avg       0.83      0.83      0.82       450\n",
            "weighted avg       0.82      0.82      0.82       450\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a composite estimator made by a pipeline of preprocessing and the KNN model\n",
        "#max_depth de 9\n",
        "model = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('ds', DecisionTreeClassifier(max_leaf_nodes=20, criterion='gini', \n",
        "                                      splitter='random', class_weight='balanced', max_depth=9))\n",
        "])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(x_train, y_train) \n",
        "\n",
        "# create a k-fold cross validation iterator of k=10 folds\n",
        "cv = KFold(10, shuffle=True, random_state=33)\n",
        "\n",
        "# by default the score used is the one returned by score method of the estimator (accuracy)\n",
        "scores = cross_val_score(model, x_digits, y_digits, cv=cv)\n",
        "def mean_score(scores):\n",
        "    return (\"Mean score: {0:.3f} (+/- {1:.3f})\").format(np.mean(scores), sem(scores))\n",
        "print(mean_score(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gChiyVuTdfzd",
        "outputId": "6b147c27-3e7f-4db9-cc22-b86875b2ac3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean score: 0.708 (+/- 0.015)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Algoritmo SVM\n",
        "\n",
        "Dado un conjunto de puntos, subconjunto de un conjunto mayor (espacio), en el que cada uno de ellos pertenece a una de dos posibles categorías, un algoritmo basado en SVM construye un modelo capaz de predecir si un punto nuevo (cuya categoría desconocemos) pertenece a una categoría o a la otra."
      ],
      "metadata": {
        "id": "Z-L6cwgYA-Fo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import svm\n",
        "clf = svm.SVC(gamma=0.001, C=100)\n",
        "\n",
        "#en este apartado se muestra una idea conceptual del funcionamiento del SVM"
      ],
      "metadata": {
        "id": "Opy7FRrnuE-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(digits.data)) #recordamos la longitud del dataset\n",
        "\n",
        "#Entrenamos con todo el array menos con los últimos 10 valores\n",
        "x,y = digits.data[:-10], digits.target[:-10]\n",
        "\n",
        "\n",
        "clf.fit(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOlRp5A8BEqb",
        "outputId": "5e9e68e6-2645-455d-9186-e905f2e3fd3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1797\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=100, gamma=0.001)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape #vemos que esto es 1797-10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeTC43heIZCD",
        "outputId": "3f43a1bb-8c01-48e9-db65-6a1adf7063c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1787, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Prediction:', clf.predict(digits.data[-2:-1]))\n",
        "#predecimos con la posición penúltima\n",
        "\n",
        "\n",
        "plt.imshow(digits.images[-2], cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "#mostramos la imagen del digito de la posición penúltima\n",
        "plt.show()\n",
        "\n",
        "#parece que sí es un 9\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "HXb7Mm3LBe1E",
        "outputId": "b0f099fa-d54e-491a-841c-0e3a92e458aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: [9]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Prediction:', clf.predict(digits.data[-6:-5]))\n",
        "#predecimos con la posición 6 empezando por el final\n",
        "#recordamos que los últimos 10 números no los hemos usado para entrenar entonces\n",
        "#tiene sentido tratar de predecirlos\n",
        "\n",
        "\n",
        "plt.imshow(digits.images[-6], cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "#mostramos la imagen del digito de la posición penúltima\n",
        "plt.show()\n",
        "\n",
        "#parece que sí es un 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "m9_TH61DIe_0",
        "outputId": "0e2403d1-11ff-4e4e-d9c9-468380e29e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: [4]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creamos el modelo SVM**\n",
        "\n",
        "El \"truco\" del kernel consiste en inventar una dimensión nueva en la que podamos encontrar un hiperplano para separar las clases.\n",
        "Vamos a hacer una comparación del modelo usando kernel lineal y kernel RBF.\n",
        "\n",
        "rbf kernel: https://en.wikipedia.org/wiki/Radial_basis_function_kernel\n",
        "\n",
        "linear kernel: https://www.geeksforgeeks.org/creating-linear-kernel-svm-in-python/ \n"
      ],
      "metadata": {
        "id": "1z3XPLFZTuuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Recordamos el tamaño del x train y el x test realizado en el apartado de preprocesado\n",
        "\n",
        "print(\"x_train.shape:\", x_train.shape)\n",
        "print(\"x_test.shape:\", x_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qJEsMwJQTU8",
        "outputId": "7fcbd328-d689-4963-ed1a-3f5961197d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape: (1347, 64)\n",
            "x_test.shape: (450, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#utilizamos linear kernel\n",
        "model_linear =svm.SVC(kernel='linear', degree=3, gamma='scale')\n",
        "model_linear.fit(x_train, y_train)\n",
        "\n",
        "y_pred = model_linear.predict(x_test)"
      ],
      "metadata": {
        "id": "CgwaiSiDRBut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#utilizamos RBF kernel\n",
        "model_RBF =svm.SVC(kernel='rbf', degree=3, gamma='scale')\n",
        "model_RBF.fit(x_train, y_train)\n",
        "\n",
        "y_pred = model_RBF.predict(x_test)"
      ],
      "metadata": {
        "id": "bCHc7pfOSHiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "predictions = model_linear.predict(x_test)\n",
        "print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ngo2KbDqSaz3",
        "outputId": "cc611eab-ebbc-4fa5-ea66-6f6b1aa4d29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        35\n",
            "           1       0.93      1.00      0.96        54\n",
            "           2       1.00      0.98      0.99        44\n",
            "           3       0.96      1.00      0.98        46\n",
            "           4       0.97      0.97      0.97        35\n",
            "           5       0.98      0.98      0.98        48\n",
            "           6       1.00      0.98      0.99        51\n",
            "           7       1.00      1.00      1.00        35\n",
            "           8       0.98      0.90      0.94        58\n",
            "           9       0.96      0.98      0.97        44\n",
            "\n",
            "    accuracy                           0.98       450\n",
            "   macro avg       0.98      0.98      0.98       450\n",
            "weighted avg       0.98      0.98      0.98       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluación del modelo**\n"
      ],
      "metadata": {
        "id": "ZLZt3dEjPe5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy of the model (linear):', model_linear.score(x_test, y_test))\n",
        "print('Accuracy of the model (RBF):', model_RBF.score(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ETsD8mHT3Sz",
        "outputId": "b595568c-3b9f-47c9-c172-1ab3319f362a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model (linear): 0.9755555555555555\n",
            "Accuracy of the model (RBF): 0.9866666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "predictions = model_linear.predict(x_test)\n",
        "print(\"LINEAR KERNEL:\\n\",classification_report(y_test, predictions))\n",
        "print(\"\\n\")\n",
        "predictions = model_RBF.predict(x_test)\n",
        "print(\"RBF KERNEL: \\n\", classification_report(y_test, predictions))\n",
        "\n",
        "#RBF da unos resultados ligeramente mejores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZd3uiE_UBxk",
        "outputId": "43d56c94-6cb3-48e6-dc9a-04f38215e47b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LINEAR KERNEL:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        35\n",
            "           1       0.93      1.00      0.96        54\n",
            "           2       1.00      0.98      0.99        44\n",
            "           3       0.96      1.00      0.98        46\n",
            "           4       0.97      0.97      0.97        35\n",
            "           5       0.98      0.98      0.98        48\n",
            "           6       1.00      0.98      0.99        51\n",
            "           7       1.00      1.00      1.00        35\n",
            "           8       0.98      0.90      0.94        58\n",
            "           9       0.96      0.98      0.97        44\n",
            "\n",
            "    accuracy                           0.98       450\n",
            "   macro avg       0.98      0.98      0.98       450\n",
            "weighted avg       0.98      0.98      0.98       450\n",
            "\n",
            "\n",
            "\n",
            "RBF KERNEL: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        35\n",
            "           1       0.98      1.00      0.99        54\n",
            "           2       1.00      0.98      0.99        44\n",
            "           3       1.00      1.00      1.00        46\n",
            "           4       0.97      0.94      0.96        35\n",
            "           5       0.98      0.98      0.98        48\n",
            "           6       0.98      1.00      0.99        51\n",
            "           7       1.00      1.00      1.00        35\n",
            "           8       0.98      0.98      0.98        58\n",
            "           9       0.98      0.98      0.98        44\n",
            "\n",
            "    accuracy                           0.99       450\n",
            "   macro avg       0.99      0.99      0.99       450\n",
            "weighted avg       0.99      0.99      0.99       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Persistencia\n",
        "\n",
        "Vamos a probar como guardar el modelo combinado entre el StandardScaler y el KNeighborsClassifier.\n",
        "\n",
        "Se puede usar pickle, diccionario que puede ser usado como un archivo o como un string, o también se puede usar joblib. "
      ],
      "metadata": {
        "id": "m0Rt0C2-fTld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "s = pickle.dumps(model)\n",
        "model2 = pickle.loads(s)\n",
        "model2.predict(x_digits[0:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9xa_2IxPyge",
        "outputId": "e56825d4-45ae-4d3c-e3c8-d09aad7fdfd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "import joblib\n",
        "joblib.dump(model, 'filename.pkl') \n",
        "\n",
        "#load model\n",
        "model2 = joblib.load('filename.pkl') "
      ],
      "metadata": {
        "id": "daejpnalP3Dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Conclusiones\n",
        "\n",
        "Esta práctica ha servido para tener una visión panóramica de los pasos que se deben seguir para afrontar un problema de clasificación: Análisis del dataset, preprocesado y normalización de los datos, definición de los sets de entrenamiento y testeo, entrenamiento del modelo, valoración de su rendimiento y optimización de sus parámetros de entrada para obtener una mejora en la predicción. \n",
        "\n",
        "Se partía de un datasets de dígitos definidos por una matriz de 8x8 píxeles, el objetivo ha sido que el modelo fuera capaz de clasificar cada conjunto de píxeles (fila) en un número de 0 al 9. El modelo que mejor resultado ha dado para ello entre los que han sido puestos a prueba ha sido el SVM. \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MJfybcSDfWJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V56C2SMXRn4I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}